{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vitasantos/CineMood---PLN/blob/main/2025_Q3_PLN_PROJETO_PR%C3%81TICO_CINEMOOD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2025-Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67OOx9MX_3"
      },
      "source": [
        "### **PROJETO CINEMOOD** [LangChain + Grandes Modelos de Linguagem]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hJlilKM485"
      },
      "source": [
        "### **EQUIPE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Integrante 01:**\n",
        "\n",
        "Gustavo Dias Marsili, RA: 11202130401\n",
        "\n",
        "**Integrante 02:**\n",
        "\n",
        "Gustavo Teodoro Bauke, RA: 11202130481\n",
        "\n",
        "**Integrante 03:**\n",
        "\n",
        "Vitória Cordeiro dos Santos, RA: 11202130706"
      ],
      "metadata": {
        "id": "tnIArN0QY-Ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GRANDE MODELO DE LINGUAGEM (*Large Language Model - LLM*)**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "VbYD2mw8y4CN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">\n",
        "\n",
        "\n",
        "**LLM**: Gemini 2.5 Flash\n",
        "\n",
        ">\n",
        "\n",
        "**Link para a documentação oficial**:\n",
        "https://ai.google.dev/gemini-api/docs?hl=pt-br\n"
      ],
      "metadata": {
        "id": "a6AkE6iW0c3o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **API**\n",
        "---"
      ],
      "metadata": {
        "id": "6yExhaebs-nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**API**: TMDb API\n",
        "\n",
        "**Site oficial**: https://www.themoviedb.org/\n",
        "\n",
        "**Link para a documentação oficial**: https://developer.themoviedb.org/docs/getting-started\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DjJM_qhEZRy6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjgWQRzNphL"
      },
      "source": [
        "### **DESCRIÇÃO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este projeto aplica técnicas de Processamento de Linguagem Natural (PLN), integrando o framework LangChain, um Grande Modelo de Linguagem (LLM) e dados obtidos de uma API externa. O objetivo é criar um sistema capaz de analisar o relato diário de um usuário, extrair informações relevantes e gerar recomendações personalizadas de filmes com base no estado emocional e no conteúdo do texto.\n",
        "\n",
        "O fluxo completo combina coleta de dados da API, análise semântica via LLM e um pipeline de prompts construído com LangChain."
      ],
      "metadata": {
        "id": "fXTwkiiGs2BV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **MOTIVAÇÃO**\n",
        "---"
      ],
      "metadata": {
        "id": "eGy7w9LSlGXX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicações modernas de recomendação precisam cada vez mais entender o contexto emocional, o significado e a intenção dos usuários. Em vez de depender apenas de histórico ou avaliações, este projeto demonstra como utilizar um LLM aliado a técnicas clássicas de PLN para interpretar textos do cotidiano e sugerir conteúdos adequados ao momento emocional do indivíduo.\n",
        "\n",
        "A ideia surgiu da pergunta:\n",
        "\"Como um sistema poderia recomendar filmes levando em conta como o usuário está se sentindo e o que ele viveu no dia?\"\n",
        "\n",
        "Este projeto, portanto, ilustra como unir:\n",
        "\n",
        "* LLM para interpretação profunda do texto;\n",
        "\n",
        "* Técnicas de PLN para extrair informações estruturadas;\n",
        "\n",
        "* Dados reais de uma API de filmes para produzir uma recomendação personalizada."
      ],
      "metadata": {
        "id": "umeyamDElUcS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TÉCNICAS DE PLN UTILIZADAS**\n",
        "---"
      ],
      "metadata": {
        "id": "sbvRFrAJmdhe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Classificação de Sentimentos\n",
        "\n",
        "##O que é:\n",
        "\n",
        "Técnica que identifica o tom emocional predominante em um texto (positivo, negativo, neutro etc.).\n",
        "\n",
        "##Como utilizamos:\n",
        "\n",
        "Criamos um PromptTemplate que instrui o LLM a classificar o texto do usuário em uma das categorias pré-definidas. Este prompt é processado com o LangChain usando LCEL.\n",
        "\n",
        "##Resultado:\n",
        "\n",
        "O sistema determina se o usuário está em um dia “positivo”, “negativo”, “neutro”, “muito positivo” ou “muito negativo”. Essa informação é utilizada posteriormente para guiar a recomendação de gêneros de filmes."
      ],
      "metadata": {
        "id": "Xhu_wUDbmnz9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Sumarização (em estilo “Logline”)\n",
        "\n",
        "##O que é:\n",
        "\n",
        "Condensar um texto longo em uma frase curta, mantendo seu núcleo de significado.\n",
        "\n",
        "##Como utilizamos:\n",
        "\n",
        "Criamos um segundo PromptTemplate, instruindo o LLM a atuar como um roteirista e transformar o relato original em uma logline cinematográfica (até 15 palavras), mantendo um tom dramático ou engraçado.\n",
        "\n",
        "##Este resumo tem dois objetivos:\n",
        "\n",
        "- Destacar o “tema central” do dia do usuário.\n",
        "\n",
        "- Servir como um elemento narrativo para a etapa de recomendação de gêneros."
      ],
      "metadata": {
        "id": "BzkI4Lugnqvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **INTEGRAÇÃO COM API EXTERNA (TMDB)**\n",
        "---"
      ],
      "metadata": {
        "id": "YiiXW4JWokEg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O sistema utiliza a API do The Movie Database (TMDB) para:\n",
        "\n",
        "- Buscar a lista oficial de gêneros de filmes;\n",
        "\n",
        "- Mapear cada gênero ao seu respectivo ID;\n",
        "\n",
        "- Após a análise de sentimentos e resumo, solicitar ao LLM que escolha dois gêneros apropriados;\n",
        "\n",
        "- Fazer uma consulta real à API buscando filmes populares nesses gêneros;\n",
        "\n",
        "- Selecionar o filme mais relevante e apresentá-lo ao usuário.\n",
        "\n",
        "Essa etapa garante que o sistema não apenas gere texto, mas também ofereça uma recomendação concreta baseada em dados reais."
      ],
      "metadata": {
        "id": "9_SVtyNjo0N3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **USO DO LANGCHAIN**\n",
        "---"
      ],
      "metadata": {
        "id": "JwkPL5papM1D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O LangChain foi utilizado como camada de orquestração entre prompts, LLM e parsing. As principais funcionalidades empregadas foram:\n",
        "\n",
        "- PromptTemplate → estruturação clara dos prompts;\n",
        "\n",
        "- LCEL (|) → criação de pipelines de processamento;\n",
        "\n",
        "- StrOutputParser → garantir saída textual consistente do LLM;\n",
        "\n",
        "- ChatGoogleGenerativeAI → integração do LangChain com o LLM Gemini."
      ],
      "metadata": {
        "id": "z9ze9fJdpRpb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMPLEMENTAÇÃO**\n",
        "---"
      ],
      "metadata": {
        "id": "nw09lujGvfjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain-google-genai google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Arc0nV_Sfbtb",
        "outputId": "fd1ee5f6-da48-40bb-a5e6-1c15073c5ac6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<1.0.0,>=0.9.0 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting langchain-core<2.0.0,>=1.0.5 (from langchain-google-genai)\n",
            "  Downloading langchain_core-1.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (2.11.10)\n",
            "INFO: pip is looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting google-generativeai\n",
            "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\n",
            "  Downloading google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.8.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "INFO: pip is still looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading google_generativeai-0.8.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.8.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading google_generativeai-0.7.2-py3-none-any.whl.metadata (4.0 kB)\n",
            "  Downloading google_generativeai-0.7.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.7.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.6.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.4-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.4.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "  Downloading google_generativeai-0.4.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "  Downloading google_generativeai-0.3.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading google_generativeai-0.3.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading google_generativeai-0.3.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading google_generativeai-0.2.2-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Downloading google_generativeai-0.2.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Downloading google_generativeai-0.2.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Downloading google_generativeai-0.1.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-3.0.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_google_genai-3.0.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_google_genai-3.0.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain_google_genai-3.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain_google_genai-2.1.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: langchain-core>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (0.3.80)\n",
            "  Downloading langchain_google_genai-2.1.11-py3-none-any.whl.metadata (6.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.10-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.8-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.6-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.10-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (0.4.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (6.0.3)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.3.75->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.25.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.11.12)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain-google-genai) (1.3.1)\n",
            "Downloading langchain_google_genai-2.0.10-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, langchain-google-genai\n",
            "Successfully installed filetype-1.2.0 langchain-google-genai-2.0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "genai.configure(api_key = GEMINI_API_KEY)"
      ],
      "metadata": {
        "id": "1gYw3UMsaUgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "modelo = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", google_api_key = GEMINI_API_KEY)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-amp4Mr5a58w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "vsTekk1Lhzpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Dl2qQRDEV7Y",
        "outputId": "2b5f44a2-cb41-4efa-84e2-b4bfd09f065b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://api.themoviedb.org/3/genre/movie/list?language=pt\"\n",
        "\n",
        "headers = {\n",
        "    \"accept\": \"application/json\",\n",
        "    \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiJhY2E5MTRmNDliZDBlYWVhYzM3NjAzMTU2MDBmZTY1MiIsIm5iZiI6MTc2MzMzNTUxOS4yNDEsInN1YiI6IjY5MWE1ZDVmZDA1ZmFkYzc3ZjgxYmVkMSIsInNjb3BlcyI6WyJhcGlfcmVhZCJdLCJ2ZXJzaW9uIjoxfQ.ImdO8p0rUZ_h9aI5K5vy8foPV4xx7Asg7vtAwJitaBk\"\n",
        "}\n",
        "\n",
        "response = requests.get(url, headers=headers)\n",
        "lista_generos = [genero['name'] for genero in response.json()['genres']]\n",
        "lista_id_generos = [genero['id'] for genero in response.json()['genres']]\n",
        "mapa_generos = {\n",
        "    genero['name']: genero['id']\n",
        "    for genero in response.json()['genres']\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "X448DPweExzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "descricao_do_dia = input()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI3IkP75-SQS",
        "outputId": "7e9507d5-3f59-4da1-d01f-f1ef38ee21c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cara, hoje foi aquele dia que parece que não acaba. Fiquei horas numa planilha de Excel que não batia os valores, meu chefe ficou me chamando toda hora no Teams. Almocei correndo um salgado frio. Cheguei em casa agora, joguei a mochila no sofá e tô com zero vontade de pensar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"texto\"],\n",
        "    template=(\n",
        "        \"Classifique o sentimento do texto como muito positivo, positivo, neutro, negativo e muito negativo. Retorne apenas o sentimento\\n\\n\"\n",
        "        \"Texto: {texto}\\n\\n\"\n",
        "        \"Categoria:\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Construir o pipeline com LCEL (LangChain Expression Language)\n",
        "chain = prompt | modelo | StrOutputParser()\n",
        "sentimento = chain.invoke({\"texto\": descricao_do_dia})\n",
        "print(f\"Categoria: {sentimento.strip()}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Po5pnnfL_D5K",
        "outputId": "c3814774-50fa-485f-b286-73eabf7b2419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categoria: muito negativo\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_resumo = PromptTemplate(\n",
        "    input_variables=[\"texto\"],\n",
        "    template=(\n",
        "        \"Atue como um roteirista de cinema.\\n\"\n",
        "        \"Resuma o relato do dia do usuário em uma única frase dramática ou engraçada (máximo 15 palavras), \"\n",
        "        \"como se fosse a 'Logline' (sinopse curta) de um filme sobre a vida dele.\\n\"\n",
        "        \"Ignore detalhes irrelevantes.\\n\\n\"\n",
        "        \"Relato original: {texto}\\n\"\n",
        "        \"Sinopse (Logline):\"\n",
        "    )\n",
        ")\n",
        "\n",
        "chain_resumo = prompt_resumo | modelo | StrOutputParser()\n",
        "# Aqui aplicamos a técnica de Sumarização\n",
        "sinopse_do_dia = chain_resumo.invoke({\"texto\": descricao_do_dia})\n",
        "\n",
        "print(f\"Sinopse Gerada (Sumarização): {sinopse_do_dia.strip()}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxwXaA_hILRR",
        "outputId": "c5aba900-79dd-4384-edba-f0cb7df3c0bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sinopse Gerada (Sumarização): **Logline:** Um guerreiro corporativo enfrenta a épica batalha de Excel, Teams e um salgado frio, buscando apenas o fim.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"texto\",\"sentimento\",\"sinopse\",\"lista_generos\"],\n",
        "    template=(\n",
        "        \"Você é um especialista em cinema e psicologia. Analise o texto do usuário: '{texto}'.\\n\"\n",
        "        \"Baseado nesta sinopse: '{sinopse}'\\n\"\n",
        "        \"E neste sentimento detectado: {sentimento}.\\n\\n\"\n",
        "        \"Regra de Recomendação:\\n\"\n",
        "        \"1. Se o usuário estiver entediado ou triste, você pode sugerir algo para animar OU algo catártico/profundo.\\n\"\n",
        "        \"2. Se o usuário estiver com energia, sugira Ação ou Suspense.\\n\"\n",
        "        \"3. NÃO recomende Comédia se o texto indicar tensão, raiva ou desejo de reflexão.\\n\\n\"\n",
        "        \"Escolha 2 gêneros desta lista: {lista_generos}.\\n\"\n",
        "        \"Retorne APENAS os nomes dos gêneros separados por vírgula.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Construir o pipeline com LCEL (LangChain Expression Language)\n",
        "chain = prompt | modelo\n",
        "resposta = chain.invoke({\"texto\": descricao_do_dia, \"sentimento\":sentimento, \"sinopse\":sinopse_do_dia, \"lista_generos\":lista_generos})\n",
        "print(f\"Gênero: {resposta.content.strip()}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMkonVovCAN6",
        "outputId": "a56a4eb5-3474-454a-eb62-1aeebbb8e7ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gênero: Animação, Fantasia\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "lista_id = [mapa_generos.get(genero) for genero in re.split(r',\\s*', resposta.content.strip())]\n",
        "ids_formatados = \",\".join(map(str, lista_id))\n",
        "query_params = {\n",
        "    \"with_genres\": ids_formatados,\n",
        "    \"sort_by\": \"popularity.desc\",\n",
        "    \"vote_count.gte\": 50,\n",
        "    \"language\": \"pt-BR\",\n",
        "    \"vote_average.gte\": 6.0\n",
        "}\n",
        "\n",
        "url_filmes = \"https://api.themoviedb.org/3/discover/movie\"\n",
        "response_filmes = requests.get(url_filmes, headers=headers, params=query_params)\n",
        "if response_filmes.status_code == 200:\n",
        "    dados = response_filmes.json()\n",
        "    melhor_filme = dados['results'][0]\n",
        "    print(\"--- Melhor Filme Encontrado ---\")\n",
        "    print(f\"Título: {melhor_filme.get('title')}\")\n",
        "    print(f\"Média de Votos: {melhor_filme.get('vote_average')}\")\n",
        "    print(f\"Visão Geral: {melhor_filme.get('overview')}\")\n",
        "\n",
        "else:\n",
        "    print(f\"Erro na requisição: {response_filmes.status_code}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TM1Sgh1bGywD",
        "outputId": "502c30b3-8ea9-458c-a263-e61ea2f11fee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Melhor Filme Encontrado ---\n",
            "Título: Demon Slayer: Kimetsu no Yaiba Castelo Infinito\n",
            "Média de Votos: 7.583\n",
            "Visão Geral: Enquanto os membros dos caçadores e os Hashira participavam de um rigoroso programa de fortalecimento coletivo, conhecido como Treinamento dos Hashira, em preparação para a batalha final contra os demônios, Muzan Kibutsuji aparece na Mansão Ubuyashiki. Com a vida do líder da organização em risco, Tanjiro e os Hashira correm até o quartel-general, mas acabam sendo lançados, pelas mãos de Muzan, em uma queda profunda rumo a um espaço misterioso para um confronto final, o Castelo Infinito.\n"
          ]
        }
      ]
    }
  ]
}